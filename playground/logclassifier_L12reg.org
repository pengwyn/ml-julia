#+OPTIONS: toc:nil

This is the logistic classifier with white noise applied and both L1 and L2 regularisation.

* Setup
  
#+BEGIN_SRC jupyter-julia :results silent 
using Revise
using Plots
pyplot()

push!(LOAD_PATH, "../src")
using Data
using LogBin
#+END_SRC

* Overlapping blobs
#+BEGIN_SRC jupyter-julia :results silent
     centres = [[0.2,0.],
              [-0.2,0.]]
     radii = [0.5, 0.5]
     data = makeCloud(centres, radii)
                 
      cont = DataContainer(data)
      X,y = extractArrays(cont)
      X_train,y_train, X_test,y_test = trainTestSplit(cont)

#+END_SRC

   First test the normal method

   #+BEGIN_SRC jupyter-julia :file images/logclassifier_L1L2_overlap_no_reg.png
      class = LogisticClassifierBinary(max_iter=10000, 位1=0., 位2=0.)
      initialiseWeights!(class, X)

      fit!(class, X_train, y_train)

      @show class.w
      @show class.b

      plot(plotFit(class, X_train, y_train),
           plotFit(class, X_test, y_test))
   xlims!(-1,1)
   ylims!(-1,1)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
: class.w = [-1.89407, 0.731653]
: class.b = -0.035016812552922764
[[file:images/logclassifier_L1L2_overlap_no_reg.png]]
   :END:
  
   Now turn on the regularisation and see how the weight parameters are affected.

   #+BEGIN_SRC jupyter-julia :file images/logclassifier_L1L2_overlap_with_reg.png
      class = LogisticClassifierBinary(max_iter=10000, 位1=10., 位2=0.5)
      initialiseWeights!(class, X)

      fit!(class, X_train, y_train)

      @show class.w
      @show class.b

      plot(plotFit(class, X_train, y_train),
           plotFit(class, X_test, y_test))
   xlims!(-1,1)
   ylims!(-1,1)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
: class.w = [-1.00664, -0.00618968]
: class.b = 0.615944523774552
[[file:images/logclassifier_L1L2_overlap_with_reg.png]]
   :END:
   
